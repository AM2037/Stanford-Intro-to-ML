function [J, grad] = costFunctionReg(theta, X, y, lambda)
%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization
%   J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using
%   theta as the parameter for regularized logistic regression and the
%   gradient of the cost w.r.t. to the parameters. 

% Initialize some useful values
m = length(y); % number of training examples

% You need to return the following variables correctly 
J = 0;
grad = zeros(size(theta));

% ====================== YOUR CODE HERE ======================
% Instructions: Compute the cost of a particular choice of theta.
%               You should set J to the cost.
%               Compute the partial derivatives and set grad to the partial
%               derivatives of the cost w.r.t. each parameter in theta
% 1st attempt, got correct values but wouldn't accept it
% h = sigmoid(X*theta);
% err = h - y;
% J = 1/(2*m) * ((-y)' * log(h)  - (1-y)' * log(1-h)) + lambda/m * sum(X*theta);
% J = (1/m) * ((-y)' * log(h) - (1-y)' * log(1-h)) + lambda/(2*m) * sum(X*theta);

% 2nd attempt (new J and grad below) same issue
% grad = (1/m) * X' * err + lambda / m * theta'; 

% h = sigmoid(X*theta(:,2:end)); % line 94 of ex2.mlx err log: index exceeds 
% number of array elements (0).

% h = sigmoid(X*theta(2:end)); % err using * incorrect dimens for mat mult
% err = h - y;

% Trying omitting theta(1) via indexing
% J = (1/m) * ((-y)' * log(h) - (1-y)' * log(1-h)) + lambda/(2*m) * sum(h);
% grad = (1/m) * X' * err + (lambda/m) * sum(h); 
% line 94 of ex2.mlx err log: index exceeds number of array elements (0).
 
% trying from notes 
h = sigmoid(X*theta);
err = h - y;
% J = -((1/m) * sum((y)' * log(h) - (1-y)' * log(1-h)) + lambda/(2*m) * sum(X*theta(2:end)));
% error using * incorrect dimens
% J = (1/m) * ((y)' * log(h) - (1-y)' * log(1-h)) + lambda/(2*m) * sum(X*theta(2:end));
% still error using * 
% J = (1/m) * sum((y).*log(h) - (1-y).*log(1-h)) + lambda/(2*m) * sum(sigmoid(X*theta(2:end)));
% grad = (1/m) * X' * err + lambda / m * sum(X*theta(2:end));
% still error using *
J = (1/m) * ((-y)' * log(h)-(1-y)' *log(1-h)) + lambda/(2*m) * sum(theta(2:end));
grad = (1/m) * X' * err;
% grad(2:end) = grad(2:end) + lambda/(2*m) * theta(2:end)'; % L and R sides diff # elements
grad(2:end) = grad(2:end) + lambda/m.*theta(2:end)';










% =============================================================

end
